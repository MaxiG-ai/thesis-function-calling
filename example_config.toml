# --- Experiment Matrix ---
# The suite will iterate through the Cartesian product of these lists.

experiment_name = "initial_tests"
results_dir = "results"
log_dir = "results/logs"
logging_level = "INFO"
input_file = "benchmarks/complex_func_bench/data/ComplexFuncBench.jsonl"
# Optional: Run specific test cases by ID. When set, only these cases will be run.
# Examples: ["Car-Rental-0", "Car-Rental-1"] or ["Travel-5", "Cross-10"]
# Leave commented out or set to null to run all cases (or use benchmark_sample_size for random sampling)
# selected_test_cases = ["Car-Rental-131"] # Cross-131, Hotels-124 (short
benchmark_sample_size = 10

# setting for max. context before compression
compact_threshold = 5000

# 1. Select keys from model_config.toml to test
enabled_models = [
    # "gpt-5",
    # "gpt-4-1",
    "gpt-4-1-mini", 
    # "gpt-5-mini",
    # "glm-4-9b",
    # "llama-31-7b",
]

# 2. Define Memory Architectures to test
enabled_memory_methods = [
    "no_strategy",
    "truncation",
    "progressive_summarization",
    # "memory_bank",
    # "ace",
]

# --- Memory Strategy Definitions ---

[memory_strategies.truncation]
type = "truncation"

[memory_strategies.memory_bank]
type = "memory_bank"
embedding_model = "BAAI/bge-small-en-v1.5" # or local path
top_k = 3

[memory_strategies.no_strategy]
type = "no_strategy"

[memory_strategies.progressive_summarization]
type = "progressive_summarization"
summarizer_model = "gpt-4-1-mini"
summary_prompt = "src/strategies/progressive_summarization/prog_sum.prompt.md"

[memory_strategies.ace]
type = "ace"
generator_model = "gpt-4-1-mini"     # Model for generating next actions
reflector_model = "gpt-4-1-mini"     # Model for analyzing mistakes
curator_model = "gpt-4-1-mini"       # Model for updating playbook
max_reflection_rounds = 1            # Reflection iterations per step
curator_frequency = 1                # Curate every N steps
playbook_token_budget = 4096         # Max playbook size in tokens